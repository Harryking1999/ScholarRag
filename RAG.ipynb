{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -qU pypdf\n",
    "# %pip install -qU langchain-unstructured\n",
    "# %pip install -qU \"unstructured[pdf]\"\n",
    "# %pip install -qU matplotlib PyMuPDF pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting texts with PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "file_path = \"data/scholar_corpus/0KCrVeiC5zEJ.pdf\"\n",
    "\n",
    "loader = PyPDFLoader(file_path)\n",
    "pages = []\n",
    "async for page in loader.alazy_load():\n",
    "    pages.append(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{pages[0].metadata}\\n\")\n",
    "print(pages[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting texts, images & tables with Unstructured API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if \"UNSTRUCTURED_API_KEY\" not in os.environ:\n",
    "    os.environ[\"UNSTRUCTURED_API_KEY\"] = getpass.getpass(\"Unstructured API Key:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_unstructured import UnstructuredLoader\n",
    "\n",
    "file_path = \"data/scholar_corpus/0KCrVeiC5zEJ.pdf\"\n",
    "\n",
    "loader = UnstructuredLoader(\n",
    "    file_path=file_path,\n",
    "    strategy=\"hi_res\",\n",
    "    partition_via_api=True,\n",
    "    coordinates=True,\n",
    ")\n",
    "docs = []\n",
    "for doc in loader.lazy_load():\n",
    "    docs.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "pprint(docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_page_docs = [doc for doc in docs if (doc.metadata.get(\"page_number\") == 1)]\n",
    "\n",
    "for doc in first_page_docs:\n",
    "    print(doc.page_content)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##fzz：建立index，这样下面的dducument数据结构才能找到coordinates里面的字段\n",
    "index_dict = {}\n",
    "for i in first_page_docs:\n",
    "    element_id = i.metadata['element_id']\n",
    "    index_dict[element_id] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(index_dict['c1ca1e8812f489e94f6cf80276f8bff6'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###fzz: 尝试输出page_content理应相连的部分\n",
    "def judge_end(st):##true就是这段话完整，False表示这段话不完整\n",
    "    if(st[len(st)-1] not in \".?!\"):##论文的段落结尾应该都是'.' 好像没见过别的\n",
    "        return False\n",
    "    else:\n",
    "        ##判断是不是没有不匹配的括号，有说明不完整(为了防止上面的if看到的是引用的句号)\n",
    "        cnt_left_bracket = 0\n",
    "        cnt_right_bracket = 0\n",
    "        for i in st:\n",
    "            if(i == \"(\"):\n",
    "                cnt_left_bracket += 1\n",
    "            if(i == \")\"):\n",
    "                cnt_right_bracket += 1\n",
    "        if(cnt_left_bracket != cnt_right_bracket):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "new_first_page_docs = []\n",
    "tmp_doc = None\n",
    "for i in range(0, len(first_page_docs)):\n",
    "    if(len(first_page_docs[i].page_content.split(\" \")) < 15):\n",
    "        new_first_page_docs.append(first_page_docs[i])\n",
    "        continue\n",
    "    if(tmp_doc == None):\n",
    "        if(judge_end(first_page_docs[i].page_content)):\n",
    "            new_first_page_docs.append(first_page_docs[i])\n",
    "        else:\n",
    "            tmp_doc = first_page_docs[i]\n",
    "    else:\n",
    "        tmp_doc.page_content += first_page_docs[i].page_content\n",
    "        # print(tmp_doc.metadata['element_id'])\n",
    "        # print(index_dict[tmp_doc.metadata['element_id']])\n",
    "        if('element_id_ls' not in index_dict[tmp_doc.metadata['element_id']].metadata.keys()):\n",
    "            index_dict[tmp_doc.metadata['element_id']].metadata['element_id_ls'] = [tmp_doc.metadata['element_id'], first_page_docs[i].metadata['element_id']]\n",
    "        else:\n",
    "            index_dict[tmp_doc.metadata['element_id']].metadata['element_id_ls'].append(first_page_docs[i].metadata['element_id'])\n",
    "        if(judge_end(tmp_doc.page_content)):\n",
    "            new_first_page_docs.append(tmp_doc)\n",
    "            tmp_doc = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in new_first_page_docs:\n",
    "    print(doc.page_content)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(first_page_docs[0].id)\n",
    "pprint(first_page_docs[0].metadata)\n",
    "print(first_page_docs[0].type)\n",
    "print(type(first_page_docs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for prop in vars(first_page_docs[0]):\n",
    "    if not prop.startswith('__'):\n",
    "        print(prop)\n",
    "# first_page_docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def plot_pdf_with_boxes(pdf_page, segments):\n",
    "    pix = pdf_page.get_pixmap()\n",
    "    pil_image = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "\n",
    "    fig, ax = plt.subplots(1, figsize=(10, 10))\n",
    "    ax.imshow(pil_image)\n",
    "    categories = set()\n",
    "    category_to_color = {\n",
    "        \"Title\": \"orchid\",\n",
    "        \"Image\": \"forestgreen\",\n",
    "        \"Table\": \"tomato\",\n",
    "    }\n",
    "    for segment in segments:\n",
    "        points = segment[\"coordinates\"][\"points\"]\n",
    "        layout_width = segment[\"coordinates\"][\"layout_width\"]\n",
    "        layout_height = segment[\"coordinates\"][\"layout_height\"]\n",
    "        scaled_points = [\n",
    "            (x * pix.width / layout_width, y * pix.height / layout_height)\n",
    "            for x, y in points\n",
    "        ]\n",
    "        box_color = category_to_color.get(segment[\"category\"], \"deepskyblue\")\n",
    "        categories.add(segment[\"category\"])\n",
    "        rect = patches.Polygon(\n",
    "            scaled_points, linewidth=1, edgecolor=box_color, facecolor=\"none\"\n",
    "        )\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "    # Make legend\n",
    "    legend_handles = [patches.Patch(color=\"deepskyblue\", label=\"Text\")]\n",
    "    for category in [\"Title\", \"Image\", \"Table\"]:\n",
    "        if category in categories:\n",
    "            legend_handles.append(\n",
    "                patches.Patch(color=category_to_color[category], label=category)\n",
    "            )\n",
    "    ax.axis(\"off\")\n",
    "    ax.legend(handles=legend_handles, loc=\"upper right\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def render_page(doc_list: list, page_number: int, print_text=True) -> None:\n",
    "    pdf_page = fitz.open(file_path).load_page(page_number - 1)\n",
    "    page_docs = [\n",
    "        doc for doc in doc_list if doc.metadata.get(\"page_number\") == page_number\n",
    "    ]\n",
    "    segments = [doc.metadata for doc in page_docs]\n",
    "    plot_pdf_with_boxes(pdf_page, segments)\n",
    "    if print_text:\n",
    "        for doc in page_docs:\n",
    "            print(f\"{doc.page_content}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render_page(docs,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform into Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores.utils import filter_complex_metadata\n",
    "# Filter out coordinates metadata which is not supported in vector store\n",
    "filtered_docs = filter_complex_metadata(docs)\n",
    "print(filtered_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain_community.embeddings import OpenAIEmbeddings\n",
    "\n",
    "chroma_store = Chroma.from_documents(\n",
    "    documents=filtered_docs,\n",
    "    embedding=OpenAIEmbeddings(),\n",
    "    persist_directory=\"scholar_embeddings\"\n",
    ")\n",
    "\n",
    "# No longer userful as docs are automatically persisted.\n",
    "# https://python.langchain.com/api_reference/community/vectorstores/langchain_community.vectorstores.chroma.Chroma.html#langchain_community.vectorstores.chroma.Chroma.persist\n",
    "# chroma_store.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ask questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_store.search('Contrastive Decoding', search_type=\"similarity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_store.search('Does this paper mentions contrastive decoding?', search_type=\"similarity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import VectorDBQA\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "model_local = ChatOllama(model=\"qwen:7b\")\n",
    "persist_directory = \"scholar_embeddings\"\n",
    "\n",
    "# TODO: Need refactor, Deprecated class\n",
    "# https://python.langchain.com/api_reference/core/vectorstores/langchain_core.vectorstores.in_memory.InMemoryVectorStore.html#langchain_core.vectorstores.in_memory.InMemoryVectorStore\n",
    "qa = VectorDBQA.from_chain_type(llm=model_local, chain_type=\"stuff\", vectorstore=chroma_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Does this paper mentions contrastive decoding?\"\n",
    "result = qa.run(query)\n",
    "\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paperRAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
